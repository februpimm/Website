{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12301923,"sourceType":"datasetVersion","datasetId":7753922},{"sourceId":12302425,"sourceType":"datasetVersion","datasetId":7754285},{"sourceId":12302978,"sourceType":"datasetVersion","datasetId":7754669},{"sourceId":12303762,"sourceType":"datasetVersion","datasetId":7755223}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re # regex\nfrom urllib.parse import urlparse, parse_qs # urlparse & parse_qs\nfrom scipy.stats import entropy # Cho url_entropy ở","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path = '/kaggle/input/labeldata/normal_labeled.log'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nfrom typing import Union, Iterable, List, Dict, Optional\nimport pandas as pd\n\n# ──────────────────────────────────────────────────────────────\n# 1) Pre-compile regex (Nginx / Apache “combined” format)\n#    - STRICT   : có dấu \" quanh request + referrer + user-agent\n#    - FALLBACK : thiếu hoặc hỏng dấu \" (bắt thoáng hơn)\n# ──────────────────────────────────────────────────────────────\nNGINX_REGEX_STRICT = re.compile(\n    r'(?P<ip>\\S+)\\s+-\\s+-\\s+'                              # IP - -\n    r'\\[(?P<timestamp>[^\\]]+)]\\s+'                         # [timestamp]\n    r'\"(?P<method>[A-Z]+)\\s+'                              # \"METHOD␣\n    r'(?P<url>.+?)\\s+'                                     # URL (non-greedy)\n    r'(?P<protocol>[A-Z]+/\\d(?:\\.\\d)?)\"\\s+'                # PROTOCOL\"\n    r'(?P<status>\\d{3}|-)\\s+'                              # status\n    r'(?P<size>\\d+|-)\\s+'                                  # size\n    r'\"(?P<referrer>[^\"]*)\"\\s+'                            # \"referrer\"\n    r'\"(?P<user_agent>[^\"]*)\"'                            # \"user-agent\"\n    r'(?:[ \\t]+(?P<label>[01]))?$',        #  ← thêm nhóm label tuỳ chọn\n    flags=re.IGNORECASE,\n)\n\nNGINX_REGEX_FALLBACK = re.compile(\n    r'(?P<ip>\\S+)\\s+-\\s+-\\s+'                              # IP - -\n    r'\\[(?P<timestamp>[^\\]]+)]\\s+'                         # [timestamp]\n    r'(?P<method>[A-Z]+)\\s+'                               # METHOD\n    r'(?P<url>.+?)\\s+'                                     # URL\n    r'(?P<protocol>[A-Z]+/\\d(?:\\.\\d)?)\\s+'                 # PROTOCOL\n    r'(?P<status>\\d{3}|-)\\s+'                              # status\n    r'(?P<size>\\d+|-)\\s+'                                  # size\n    r'(?P<referrer>\\S+|-)\\s+'                              # referrer (không quotes)\n    r'(?P<user_agent>.+)'                                 # user-agent (còn lại)\n    r'(?:[ \\t]+(?P<label>[01]))?$',        #  ← thêm nhóm label tuỳ chọn\n\n    flags=re.IGNORECASE,\n)\n\n# Gộp thành tuple để lần lượt thử\nNGINX_COMBINED_PATTERNS = (NGINX_REGEX_STRICT, NGINX_REGEX_FALLBACK)\n\n# ──────────────────────────────────────────────────────────────\n# 2) Tiện ích: loại bỏ ký tự control (nếu log bị lẫn \\x00 …)\n# ──────────────────────────────────────────────────────────────\ndef strip_control(s: str) -> str:\n    \"\"\"Remove leading control chars (0x00–0x1F) ở đầu dòng.\"\"\"\n    return re.sub(r'^[\\x00-\\x1F]+', \"\", s)\n\n# ──────────────────────────────────────────────────────────────\n# 3) Hàm wrapper parse_nginx_log\n# ──────────────────────────────────────────────────────────────\ndef parse_nginx_log(\n    source: Union[str, Iterable[str]],\n    patterns: Iterable[re.Pattern] = NGINX_COMBINED_PATTERNS,\n    as_dataframe: bool = True,\n    encoding: Optional[str] = \"utf-8\",\n) -> Union[pd.DataFrame, List[Dict[str, str]]]:\n    \"\"\"\n    Parse log Nginx / Apache (combined) thành list[dict] hoặc pandas.DataFrame.\n\n    Args:\n        source (str | Iterable[str]):\n            • Chuỗi đường dẫn file, hoặc\n            • Iterable (list, generator, ...) các dòng log.\n        patterns (Iterable[re.Pattern]): Danh sách regex sẽ thử lần lượt.\n        as_dataframe (bool): True -> trả về DataFrame, False -> list[dict].\n        encoding (str | None): Encoding khi mở file (nếu source là path).\n\n    Returns:\n        pandas.DataFrame | list[dict]\n    \"\"\"\n    # 1) Lấy iterator dòng log\n    if isinstance(source, str):                # truyền path\n        fh = open(source, \"r\", encoding=encoding, errors=\"replace\")\n        lines = fh\n        close_file = True\n    else:                                      # iterable dòng\n        lines = source\n        close_file = False\n\n    # 2) Parse\n    parsed: List[Dict[str, str]] = []\n    for raw_line in lines:\n        line = strip_control(raw_line.rstrip(\"\\n\"))\n        for pat in patterns:\n            m = pat.match(line)\n            if m:\n                parsed.append(m.groupdict())\n                break                          # matched → sang dòng kế\n        # nếu muốn ghi lại MISS, thêm else: missed.append(line)\n\n    # 3) Đóng file nếu cần\n    if close_file:\n        fh.close()\n\n    # 4) Trả kết quả\n    return pd.DataFrame(parsed) if as_dataframe else parsed","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# stores output in parsed_log.csv\nimport pandas as pd\ndf = parse_nginx_log(path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.dropna(subset=['label'], inplace=True)\ndf['label'] = df['label'].astype(int)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, test_df = train_test_split(\n    df, \n    test_size=0.2, \n    random_state=42,\n    stratify=df['label'] # Rất quan trọng để giữ tỷ lệ label trong cả 2 tập\n)\n\nprint(\"Kích thước tập Train:\", train_df.shape)\nprint(\"Kích thước tập Test:\", test_df.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isna().sum()/len(df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.sample(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Time-based feature handling","metadata":{}},{"cell_type":"code","source":"def timestamp_features(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Nhận vào một DataFrame chứa cột 'timestamp' và trả về DataFrame\n    đã được bổ sung đầy đủ các feature về thời gian.\n    \"\"\"\n    df['timestamp_dt'] = pd.to_datetime(df['timestamp'], format='%d/%b/%Y:%H:%M:%S %z', errors='coerce')\n    \n    df = df.sort_values('timestamp_dt').reset_index(drop=True)\n\n    df['hour_of_day'] = df['timestamp_dt'].dt.hour\n    df['day_of_week'] = df['timestamp_dt'].dt.dayofweek\n    df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n\n    def get_part_of_day(hour):\n        if 5 <= hour < 12:\n            return 'morning'\n        elif 12 <= hour < 17:\n            return 'afternoon'\n        elif 17 <= hour < 21:\n            return 'evening'\n        else:\n            return 'night'\n    df['part_of_day'] = df['hour_of_day'].apply(get_part_of_day)\n\n    df['hour_sin'] = np.sin(2 * np.pi * df['hour_of_day'] / 24)\n    df['hour_cos'] = np.cos(2 * np.pi * df['hour_of_day'] / 24)\n    df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n    df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n    \n    df['time_since_last_event'] = df['timestamp_dt'].diff().dt.total_seconds().fillna(0)\n    df.drop(columns=[\"timestamp_dt\"], inplace=True)\n    df.drop(columns=[\"timestamp\"], inplace=True)\n\n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = timestamp_features(df)\ndf.sample(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature extraction process","metadata":{}},{"cell_type":"markdown","source":"## URL Feature handling","metadata":{}},{"cell_type":"markdown","source":"## URL Suspicious Patterns","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom urllib.parse import unquote_plus\nimport base64\n\n# ==============================================================================\n# HÀM PHÂN TÍCH CUỐI CÙNG (DANH SÁCH PATTERN ĐÃ ĐƯỢC DỌN DẸP)\n# ==============================================================================\ndef final_url_analyzer(url_string: str) -> tuple:\n    \"\"\"\n    Hàm cuối cùng, với danh sách pattern đã được dọn dẹp và sửa lỗi.\n    \"\"\"\n    # --- BỘ QUY TẮC ĐÃ ĐƯỢC TINH GỌN VÀ SỬA LỖI ---\n    patterns = [\n        # --- SQL Injection ---\n        r'(union\\s+select)',\n        r'(select\\s+.*\\s+from)',\n        r'(insert\\s+into)',\n        r'(delete\\s+from)',\n        r'(drop\\s+table)',\n        r'(--|#|\\/\\*|;\\s*--)',\n        r'(load_file\\s*\\()',\n        r'(information_schema\\.)',\n        r'(pg_sleep|waitfor\\s+delay|sleep|benchmark)\\s*\\(',\n        r'(xp_cmdshell)',\n        # <<< Sửa lỗi cho log #7: bắt OR '1'='1 và các dạng tương tự >>>\n        r\"(?:'|\\\")\\s*or\\s+(?:'|\\\")?.+?(?:'|\\\")?\\s*=\\s*(?:'|\\\")?.+?(?:'|\\\")?\",\n\n        # --- XSS ---\n        r'(<script)',\n        r'(<iframe)',\n        r'(<svg)',\n        r'(<img\\s+[^>]*src\\s*=\\s*[\\'\"]?javascript:)',\n        r'(on(error|load|mouseover)\\s*=)',\n        r'(eval\\s*\\()',\n        r'(document\\.cookie)',\n        r'(alert\\s*\\()',\n\n        # --- Path Traversal & File Inclusion ---\n        r'(\\.\\.\\/|\\.\\.\\\\|%2e%2e|%c0%ae)',\n        r'(etc\\/(passwd|shadow))',\n        r'(proc\\/(self|environ))',\n        r'(boot\\.ini|win\\.ini)',\n        r'(php|file|data):\\/\\/',\n\n        # --- Command Injection ---\n        r'(&&|;|\\||`|\\$\\()',\n        r'(\\b(cat|ls|whoami|id|wget|curl|bash|sh|cmd)\\s+)',\n        r'(\\/bin\\/(ba)?sh)',\n    ]\n    combined_pattern = re.compile('|'.join(patterns), re.IGNORECASE)\n\n    strings_to_check = set()\n    try:\n        strings_to_check.add(url_string)\n        decoded_url = unquote_plus(unquote_plus(url_string))\n        strings_to_check.add(decoded_url)\n    except:\n        decoded_url = url_string\n\n    # Tách các phần và thử decode hex/base64\n    parts = re.split(r'[=,&;/?]', decoded_url)\n    for part in parts:\n        part = part.strip()\n        if len(part) < 4:\n            continue\n        # hex\n        try:\n            if all(c in '0123456789abcdefABCDEF' for c in part) and len(part) % 2 == 0:\n                strings_to_check.add(bytes.fromhex(part).decode('utf-8', 'ignore'))\n        except:\n            pass\n        # base64\n        try:\n            missing_padding = len(part) % 4\n            if missing_padding:\n                part += '=' * (4 - missing_padding)\n            strings_to_check.add(base64.b64decode(part).decode('utf-8', 'ignore'))\n        except:\n            pass\n\n    # Quét từng chuỗi\n    for text in strings_to_check:\n        match = combined_pattern.search(text)\n        if match:\n            return 1\n\n    return 0\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[df[['url', 'method', 'protocol']].isnull().any(axis=1)]['url']\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[['is_suspicious']] = df['url'].apply(lambda x: pd.Series(final_url_analyzer(x)))\ndf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## User Agent Features","metadata":{}},{"cell_type":"code","source":"from user_agents import parse\n\ndef calculate_entropy(text_string: str) -> float:\n    \"\"\"\n    Tính entropy của chuỗi ký tự (dựa trên xác suất xuất hiện ký tự).\n    \"\"\"\n    import math\n    from collections import Counter\n\n    if not text_string:\n        return 0.0\n\n    counts = Counter(text_string)\n    total = len(text_string)\n    entropy = -sum((count / total) * math.log2(count / total) for count in counts.values())\n    return entropy\n\n\ndef user_agent_features(df):\n    \"\"\"\n    Thêm các đặc trưng liên quan đến User-Agent vào DataFrame đầu vào.\n    \"\"\"\n    df = df.copy()  # tránh tác động trực tiếp\n\n    df['ua_parsed'] = df['user_agent'].astype(str).apply(parse)\n\n    # 1. Trình duyệt (Browser Family)\n    df['ua_browser_family'] = df['ua_parsed'].apply(lambda ua: ua.browser.family)\n\n    # 2. Phiên bản trình duyệt (Major Version)\n    df['ua_browser_version_major'] = df['ua_parsed'].apply(lambda ua: ua.browser.version[0] if ua.browser.version else None)\n\n    # 3. Hệ điều hành (OS Family)\n    df['ua_os_family'] = df['ua_parsed'].apply(lambda ua: ua.os.family)\n\n    # 4. Phiên bản hệ điều hành (Major Version)\n    df['ua_os_version_major'] = df['ua_parsed'].apply(lambda ua: ua.os.version[0] if ua.os.version else None)\n\n    # 5. Thiết bị (Device Family/Brand)\n    df['ua_device_family'] = df['ua_parsed'].apply(lambda ua: ua.device.family)\n    df['ua_device_brand'] = df['ua_parsed'].apply(lambda ua: ua.device.brand)\n\n    # 6-10. Các flag nhận diện thiết bị\n    df['ua_is_bot'] = df['ua_parsed'].apply(lambda ua: int(ua.is_bot))\n    df['ua_is_mobile'] = df['ua_parsed'].apply(lambda ua: int(ua.is_mobile))\n    df['ua_is_tablet'] = df['ua_parsed'].apply(lambda ua: int(ua.is_tablet))\n    df['ua_is_pc'] = df['ua_parsed'].apply(lambda ua: int(ua.is_pc))\n    df['ua_is_touch_capable'] = df['ua_parsed'].apply(lambda ua: int(ua.is_touch_capable))\n\n    # 11. Độ dài chuỗi User-Agent\n    df['ua_length'] = df['user_agent'].astype(str).apply(len)\n\n    # 12. Entropy của User-Agent\n    df['ua_entropy'] = df['user_agent'].astype(str).apply(calculate_entropy)\n\n    tools = ['sqlmap', 'curl', 'wget', 'nmap', 'nikto', 'fuzz', 'hydra']\n    df['ua_is_tool'] = df['user_agent'].str.lower().apply(lambda ua: any(tool in ua for tool in tools)).astype(int)\n\n    # Dọn bộ nhớ\n    df.drop('ua_parsed', axis=1, inplace=True)\n\n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = user_agent_features(df)\ndf.sample(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cols_to_show_ua = [\n    'user_agent', 'ua_browser_family', 'ua_os_family', 'ua_device_brand',\n    'ua_is_bot', 'ua_is_mobile', 'ua_is_pc', 'ua_length', 'ua_entropy', 'ua_'\n]\n\nprint(\"\\n--- Features từ User-Agent ---\")\nprint(df[[col for col in cols_to_show_ua if col in df.columns]].head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def status_features(df):\n    \"\"\"\n    Trích xuất các feature từ cột 'status' và 'size' trong log web.\n\n    Args:\n        df (pd.DataFrame): DataFrame chứa ít nhất 2 cột: 'status' (int), 'size' (int)\n\n    Returns:\n        pd.DataFrame: DataFrame gốc kèm thêm các cột đặc trưng mới.\n    \"\"\"\n    # Kiểm tra cột trước\n    if 'status' not in df.columns or 'size' not in df.columns:\n        raise ValueError(\"DataFrame cần có cột 'status' và 'size'.\")\n\n    df = df.copy()\n    df['status'] = pd.to_numeric(df['status'], errors='coerce').fillna(0).astype(int)\n    df['size'] = pd.to_numeric(df['size'], errors='coerce').fillna(0).astype(int)\n    # 1. 4xx - lỗi phía client\n    df['status_is_client_error'] = df['status'].apply(lambda x: 1 if 400 <= x < 500 else 0)\n\n    # 2. 5xx - lỗi phía server\n    df['status_is_server_error'] = df['status'].apply(lambda x: 1 if 500 <= x < 600 else 0)\n\n    # 3. Lỗi nói chung\n    df['status_is_error'] = ((df['status_is_client_error'] == 1) | (df['status_is_server_error'] == 1)).astype(int)\n\n    # 4. Thành công (2xx)\n    df['status_is_success'] = df['status'].apply(lambda x: 1 if 200 <= x < 300 else 0)\n\n    # 5. Redirect (3xx)\n    df['status_is_redirect'] = df['status'].apply(lambda x: 1 if 300 <= x < 400 else 0)\n\n    # 6. Response size bằng 0\n    df['size_is_zero'] = df['size'].apply(lambda x: 1 if x == 0 else 0)\n\n    return df\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = status_features(df)\ndf.sample(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = referrer_features(df)\ndf.sample(3)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def behavior_features(df):\n#     df = df.copy()\n\n#     df['ip_request_count_total'] = df.groupby('ip')['ip'].transform('count')\n#     df['ip_error_rate'] = df.groupby('ip')['status_is_error'].transform('mean')\n#     df['ip_avg_query_count'] = df.groupby('ip')['url_query_count'].transform('mean')\n\n#     return df\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df = behavior_features(df)\n# df.sample(3)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data preprocessing 2","metadata":{}},{"cell_type":"code","source":"len(num_col)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(cat_col)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_col","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Đã trích xuất nên drop\n#df.drop(columns=[\"ip\", \"url\", \"referrer\"], inplace=True)\ndf.drop(columns=['user_agent'], inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.drop(columns=[\"ip\", \"url\", \"referrer\"], inplace=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isna().sum()/len(df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.drop(columns=['ua_device_brand', 'ua_browser_version_major', 'ua_os_version_major'], inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ncat_col = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n\nnum_col = df.select_dtypes(include=[\"number\"]).columns.tolist()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 7: Áp dụng Feature Engineering\nprint(\"Processing Train set...\")\ntrain_featured = timestamp_features(train_df)\n# train_featured['is_suspicious'] = train_featured['url'].apply(final_url_analyzer)\n# train_featured = user_agent_features(train_featured)\ntrain_featured = status_features(train_featured)\ntrain_featured = referrer_features(train_featured)\n# ... nếu có behavior_features, bạn phải fit trên train và transform cả hai ...\n\n\nprint(\"Processing Test set...\")\ntest_featured = timestamp_features(test_df)\n# test_featured['is_suspicious'] = test_featured['url'].apply(final_url_analyzer)\n# test_featured = user_agent_features(test_featured)\ntest_featured = status_features(test_featured)\ntest_featured = referrer_features(test_featured)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isna().sum()/len(df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df[~df['label'].isna()]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 8: Chuẩn bị X, y\nTARGET = 'label'\nua_cols_to_drop = [col for col in train_featured.columns if col.startswith('ua_')]\n\n# Dọn dẹp các cột không cần thiết cho model\ncols_to_drop = [\n    'ip', 'url', 'referrer', 'user_agent', \n    'ua_browser_version_major', 'ua_os_version_major', 'ua_device_brand', 'is_suspicious', 'ua_is_tool', 'status_is_error'\n] + ua_cols_to_drop\n\nX_train = train_featured.drop(columns=[TARGET] + [col for col in cols_to_drop if col in train_featured.columns])\ny_train = train_featured[TARGET]\n\nX_test = test_featured.drop(columns=[TARGET] + [col for col in cols_to_drop if col in test_featured.columns])\ny_test = test_featured[TARGET]\n\n# Đảm bảo các cột trong X_train và X_test khớp nhau\nX_test = X_test[X_train.columns]\n\n# Cell 9: Huấn luyện CatBoost (giống như code của bạn)\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.metrics import classification_report\n\ncat_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n\ntrain_pool = Pool(X_train, y_train, cat_features=cat_features)\ntest_pool = Pool(X_test, y_test, cat_features=cat_features)\n\nmodel = CatBoostClassifier(\n    verbose=100, \n    random_state=42,\n    # Thêm các tham số chống overfitting nếu cần\n    # auto_class_weights='Balanced', # Thử cái này nếu dữ liệu mất cân bằng\n    # early_stopping_rounds=50 \n)\n\n# Để dùng early_stopping_rounds, bạn cần fit với eval_set\n# model.fit(train_pool, eval_set=test_pool) \nmodel.fit(train_pool) # Hoặc fit như cũ\n\n# Đánh giá\ny_pred = model.predict(test_pool)\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\\\n--- Feature Importance ---\")\n\n# Lấy độ quan trọng\nfeature_importances = model.get_feature_importance()\nfeature_names = X_train.columns\n\n# Tạo DataFrame để dễ xem\nimportance_df = pd.DataFrame({\n    'feature': feature_names,\n    'importance': feature_importances\n}).sort_values(by='importance', ascending=False)\n\nprint(importance_df.head(20)) # In ra 20 feature quan trọng nhất\n\n# Vẽ biểu đồ\nplt.figure(figsize=(12, 10))\nsns.barplot(x='importance', y='feature', data=importance_df.head(20))\nplt.title('Top 20 Feature Importances')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\nimport json\n\n# Giả sử bạn vừa train xong CatBoost model:\n# model = CatBoostClassifier(...)\n# model.fit(X_train, y_train)\n\n# Cấu hình lưu kèm: các cột đã dùng và feature categorical\nmodel_columns = X_train.columns.tolist()\ncategorical_features = [col for col in model_columns if str(X_train[col].dtype) == 'category']\n\n# --- Lưu model ---\njoblib.dump(model, '/kaggle/working/catboost_model.joblib')\n\n# --- Lưu cấu hình (các cột & categorical) ---\nconfig = {\n    'model_columns': model_columns,\n    'categorical_features': categorical_features,\n}\n\nwith open('/kaggle/working/model_config.json', 'w') as f:\n    json.dump(config, f)\n\nprint(\"✅ Đã lưu model và cấu hình vào /kaggle/working/\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}